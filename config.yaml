# Имя задания
name: simple-python-script
# Описание задания
desc: Program description

# Параметры точки входа для запуска вычислений
cmd: >  # многострочная строка YAML
  python3 src/main.py
    --params ${PARAMS}
    --features ${<идентификатор_коннектора>}/features.tsv
    --validate ${CIFAR}/val.json
    --normalizer ${DS_PROJECT_HOME}/misc/norm.bin
    --model ${MODEL}
    --epochs 5

# Файлы с входными данными
inputs:
  - misc/logging.yaml  # Путь к файлу относительно директории запуска задания на локальном компьютере
  - /usr/share/params.json: # Абсолютный путь к файлу на локальном компьютере сохранен в переменную PARAMS
      var: PARAMS

# Файлы с результатами
outputs:
  - data/model.bin: MODEL  # Относительный путь к файлу сохранен в переменную MODEL
  - other/metrics.png  # Относительный путь к файлу

# Ресурсы, необходимые для запуска задания, должны быть доступны в проекте
s3-mounts: # Коннекторы S3
  - <идентификатор_коннектора>   # Идентификатор коннектора S3
                           # Имя коннектора не задано, поэтому обращение к коннектору возможно по его идентификатору
datasets:
  - <идентификатор_датасета>:  # Идентификатор датасета, доступного в проекте
      var: CIFAR   # CIFAR — переменная для обращения к датасету

# Параметры окружения
env:
  vars:  # Переменные окружения
    - DEVICE_COUNT: 8    # значение переменной окружения можно указать явно
    - PYTHONBUFFERED     # если параметр не задан, его значение будет определено из текущего окружения
  docker: <идентификатор_Docker-образа>  # Docker-образ, доступный в проекте DataSphere
  # Также можно указать Docker-образ в реестре образов
  # docker:
  #   image: <путь_к_образу_в_реестре>:<тег>  # Например <cr.yandex/crtabcdef12345678900/myenv:0.1>
                                              # Для Docker Hub достаточно указать `<имя>:<тег>`, например `ubuntu:focal`
  #   username: <логин>
  #   password: 
  #     secret-id: PASSWORD  # имя секрета DataSphere

  # Способ сборки зависимостей окружения
  python: auto # Полная автоматизация сборки окружения

  # python: # Параметры окружения задаются вручную. Если параметры не заданы, их значения будут определены из текущего окружения автоматически
  # type: manual
  # version: 3.10.13 # Версия Python
  # pip:
  #   index-url: https://pypi.org/simple # Адрес основного репозитория для установки пакетов
  #   extra-index-urls: # Адреса дополнительных репозиториев
  #     - https://pypi.ngc.nvidia.com
  #   trusted-hosts: # Список доверенных хостов
  #     - nvidia.com
  #   no-deps: true  # По умолчанию false
  # requirements-file: requirements.txt  # Файл с параметрами окружения
  # root-path:   # Явное указание дополнительных точек входа
  #   - other.py
  # local-paths: # Список локальных Python-файлов, которые нужно перенести. Нельзя использовать с опцией root-paths
  #  - foo.py
  #  - lib/ 

# Флаги запуска задания
flags:
  - attach-project-disk # Смонтировать хранилище проекта

# Конфигурации вычислительных ресурсов для запуска задания
cloud-instance-types:
  - g2.1 # Приоритетная конфигурация
  - g1.1 # Конфигурация с вторым приоритетом

# Конфигурация расширенной рабочей директории
working-storage:
  type: SSD    # тип используемого диска. Опционально, по умолчанию SSD. Доступные значения: SSD
  size: 150Gb  # размер рабочей директории в интервале 100 ГБ — 10 ТБ

# Конфигурация плавного завершения работы
graceful-shutdown:
  signal: SIGTERM  # Сигнал, который будет отправлен процессу задания при нажатии Ctrl + C (cancel), по умолчанию SIGTERM
                   # Доступные значения: SIGTERM, SIGINT, SIGHUP, SIGUSR1, SIGUSR2
  timeout: 15s     # Таймаут, через который процесс задания получит SIGKILL, если не успевает завершиться

# Список датасетов, которые будут созданы при успешном завершении задания
output-datasets:
  - name: job-test-dataset-1  # Название датасета
    var: OUT_DS               # Переменная, содержащая путь до датасета. Содержимое указанной директории будет оформлено в виде датасета
    description: "Описание"
    size: 100Gb               # Максимальный объем данных в датасете
    labels:                   # Произвольный список меток, которые будут присвоены датасету
      a: b
      c: d

# Настройка подключеня к кластеру DataProc через Spark Connector
spark:
  connector: <идентификатор_коннектора> # Идентификатор Spark Connector
